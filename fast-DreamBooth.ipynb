{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arojasflores/Blog-php/blob/master/fast-DreamBooth.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEsNHTtVlbkV"
      },
      "source": [
        "# **Colab Pro notebook from https://github.com/TheLastBen/fast-stable-diffusion**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q torch --upgrade\n",
        "!pip install -q transformers --upgrade\n"
      ],
      "metadata": {
        "id": "NUy_El-4rCSO",
        "outputId": "b249af5c-d8e2-49e9-d99a-302cde9135dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m821.2/821.2 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.1/393.1 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m118.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m98.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.7/897.7 kB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.2/200.2 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m59.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.2/158.2 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.6/216.6 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m63.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.3/89.3 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.7/155.7 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m92.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[33mWARNING: Error parsing dependencies of pytorch-lightning: .* suffix can only be used with `==` or `!=` operators\n",
            "    torch (>=1.9.*)\n",
            "           ~~~~~~^\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Error parsing dependencies of torchsde: .* suffix can only be used with `==` or `!=` operators\n",
            "    numpy (>=1.19.*) ; python_version >= \"3.7\"\n",
            "           ~~~~~~~^\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q numpy --upgrade"
      ],
      "metadata": {
        "id": "4s3E2nFsq-Mc",
        "outputId": "061ad56b-e21b-4c7a-b234-a598f761bbf0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.9/16.9 MB\u001b[0m \u001b[31m87.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[33mWARNING: Error parsing dependencies of pytorch-lightning: .* suffix can only be used with `==` or `!=` operators\n",
            "    torch (>=1.9.*)\n",
            "           ~~~~~~^\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Error parsing dependencies of torchsde: .* suffix can only be used with `==` or `!=` operators\n",
            "    numpy (>=1.19.*) ; python_version >= \"3.7\"\n",
            "           ~~~~~~~^\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "basicsr-fixed 1.4.2 requires lmdb, which is not installed.\n",
            "mediapipe 0.10.20 requires jax, which is not installed.\n",
            "rembg 2.0.30 requires asyncer~=0.0.2, which is not installed.\n",
            "rembg 2.0.30 requires filetype~=1.2.0, which is not installed.\n",
            "rembg 2.0.30 requires imagehash~=4.3.1, which is not installed.\n",
            "rembg 2.0.30 requires watchdog~=2.1.9, which is not installed.\n",
            "gfpgan 1.3.8 requires basicsr>=1.4.2, which is not installed.\n",
            "gfpgan 1.3.8 requires lmdb, which is not installed.\n",
            "tb-nightly 2.11.0a20221004 requires tensorboard-plugin-wit>=1.6.0, which is not installed.\n",
            "realesrgan 0.3.0 requires basicsr>=1.4.2, which is not installed.\n",
            "optax 0.2.4 requires jax>=0.4.27, which is not installed.\n",
            "orbax-checkpoint 0.11.13 requires jax>=0.5.0, which is not installed.\n",
            "dopamine-rl 4.1.2 requires jax>=0.1.72, which is not installed.\n",
            "dopamine-rl 4.1.2 requires tensorflow>=2.2.0, which is not installed.\n",
            "dopamine-rl 4.1.2 requires tensorflow-probability>=0.13.0, which is not installed.\n",
            "flax 0.10.6 requires jax>=0.5.1, which is not installed.\n",
            "keras-hub 0.18.1 requires tensorflow-text; platform_system != \"Darwin\", which is not installed.\n",
            "chex 0.1.89 requires jax>=0.4.27, which is not installed.\n",
            "mediapipe 0.10.20 requires numpy<2, but you have numpy 2.3.0 which is incompatible.\n",
            "mediapipe 0.10.20 requires protobuf<5,>=4.25.3, but you have protobuf 3.20.3 which is incompatible.\n",
            "rembg 2.0.30 requires click~=8.1.3, but you have click 8.2.1 which is incompatible.\n",
            "rembg 2.0.30 requires fastapi~=0.87.0, but you have fastapi 0.94.0 which is incompatible.\n",
            "rembg 2.0.30 requires numpy~=1.23.5, but you have numpy 2.3.0 which is incompatible.\n",
            "rembg 2.0.30 requires onnxruntime~=1.13.1, but you have onnxruntime 1.20.1 which is incompatible.\n",
            "rembg 2.0.30 requires opencv-python-headless~=4.6.0.66, but you have opencv-python-headless 4.11.0.86 which is incompatible.\n",
            "rembg 2.0.30 requires pillow~=9.3.0, but you have pillow 11.2.1 which is incompatible.\n",
            "rembg 2.0.30 requires pooch~=1.6.0, but you have pooch 1.8.2 which is incompatible.\n",
            "rembg 2.0.30 requires scikit-image~=0.19.3, but you have scikit-image 0.24.0 which is incompatible.\n",
            "rembg 2.0.30 requires scipy~=1.9.3, but you have scipy 1.15.3 which is incompatible.\n",
            "rembg 2.0.30 requires tqdm~=4.64.1, but you have tqdm 4.67.1 which is incompatible.\n",
            "rembg 2.0.30 requires uvicorn~=0.20.0, but you have uvicorn 0.18.3 which is incompatible.\n",
            "tensorboardx 2.5.1 requires protobuf<=3.20.1,>=3.8.0, but you have protobuf 3.20.3 which is incompatible.\n",
            "blendmodes 2022 requires numpy<2,>=1.22.1, but you have numpy 2.3.0 which is incompatible.\n",
            "blendmodes 2022 requires Pillow<10,>=9.0.0, but you have pillow 11.2.1 which is incompatible.\n",
            "clean-fid 0.1.31 requires requests==2.25.1, but you have requests 2.28.2 which is incompatible.\n",
            "tb-nightly 2.11.0a20221004 requires google-auth-oauthlib<0.5,>=0.4.1, but you have google-auth-oauthlib 1.2.2 which is incompatible.\n",
            "tb-nightly 2.11.0a20221004 requires tensorboard-data-server<0.7.0,>=0.6.0, but you have tensorboard-data-server 0.7.2 which is incompatible.\n",
            "scikit-learn 1.3.2 requires numpy<2.0,>=1.17.3, but you have numpy 2.3.0 which is incompatible.\n",
            "ucxx-cu12 0.42.0 requires pynvml<13.0.0a0,>=12.0.0, but you have pynvml 11.4.1 which is incompatible.\n",
            "ucx-py-cu12 0.42.0 requires pynvml<13.0.0a0,>=12.0.0, but you have pynvml 11.4.1 which is incompatible.\n",
            "pymc 5.23.0 requires rich>=13.7.1, but you have rich 13.3.1 which is incompatible.\n",
            "cupy-cuda12x 13.3.0 requires numpy<2.3,>=1.22, but you have numpy 2.3.0 which is incompatible.\n",
            "dask-cuda 25.2.0 requires pynvml<13.0.0a0,>=12.0.0, but you have pynvml 11.4.1 which is incompatible.\n",
            "ydf 0.12.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 3.20.3 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.0 which is incompatible.\n",
            "thinc 8.3.6 requires pydantic<3.0.0,>=2.0.0, but you have pydantic 1.10.2 which is incompatible.\n",
            "yfinance 0.2.61 requires requests>=2.31, but you have requests 2.28.2 which is incompatible.\n",
            "yfinance 0.2.61 requires websockets>=13.0, but you have websockets 10.4 which is incompatible.\n",
            "dask-cudf-cu12 25.2.2 requires pynvml<13.0.0a0,>=12.0.0, but you have pynvml 11.4.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from diffusers import StableDiffusionPipeline\n",
        "from torch import cuda\n",
        "from accelerate import Accelerator\n",
        "import torch\n",
        "\n",
        "# Inicializa el acelerador de entrenamiento\n",
        "accelerator = Accelerator()\n",
        "\n",
        "# Define las rutas y parámetros\n",
        "instance_data_dir = \"/content/data/sks-alba\"  # Ruta a tus imágenes\n",
        "instance_prompt = \"a photo of sks-alba person\"\n",
        "output_dir = \"/content/output\"\n",
        "train_steps = 800  # Número de pasos\n",
        "batch_size = 1\n",
        "\n",
        "# Cargar el modelo de Stable Diffusion\n",
        "pipe = StableDiffusionPipeline.from_pretrained(\"runwayml/stable-diffusion-v1-5\")\n",
        "pipe.to(cuda.current_device())  # Enviar el modelo a la GPU\n",
        "\n",
        "# Preparar el optimizador y el planificador de entrenamiento\n",
        "optimizer = torch.optim.AdamW(pipe.unet.parameters(), lr=1e-5)\n",
        "\n",
        "# Inicia el ciclo de entrenamiento\n",
        "for step in range(train_steps):\n",
        "    # Aquí podrías incluir la lógica de entrenamiento real (como pasar las imágenes)\n",
        "\n",
        "    if step % 100 == 0:\n",
        "        print(f\"Entrenamiento paso {step}/{train_steps}...\")\n",
        "\n",
        "# Guarda el modelo entrenado\n",
        "pipe.save_pretrained(output_dir)\n"
      ],
      "metadata": {
        "id": "QtYYdjI4qz73",
        "outputId": "f3d66f07-95e9-49aa-cc8e-dbc99c88b459",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-781322ec7735>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdiffusers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStableDiffusionPipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0maccelerate\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAccelerator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/diffusers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdummy_onnx_objects\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa F403\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpipelines\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOnnxRuntimeModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/diffusers/pipelines/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdummy_pt_objects\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa F403\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdance_diffusion\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDanceDiffusionPipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mddim\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDDIMPipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mddpm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDDPMPipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/diffusers/pipelines/dance_diffusion/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpipeline_dance_diffusion\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDanceDiffusionPipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/diffusers/pipelines/dance_diffusion/pipeline_dance_diffusion.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandn_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAudioPipelineOutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDiffusionPipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/diffusers/pipelines/pipeline_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfiguration_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConfigMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodeling_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_LOW_CPU_MEM_USAGE_DEFAULT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedulers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscheduling_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSCHEDULER_CONFIG_NAME\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m from ..utils import (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/diffusers/models/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_torch_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mautoencoder_kl\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoencoderKL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcontrolnet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mControlNetModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdual_transformer_2d\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDualTransformer2DModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/diffusers/models/autoencoder_kl.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseOutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_forward_hook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmodeling_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModelMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mvae\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDecoderOutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDiagonalGaussianDistribution\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/diffusers/models/vae.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseOutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandn_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0munet_2d_blocks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mUNetMidBlock2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_down_block\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_up_block\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/diffusers/models/unet_2d_blocks.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdaGroupNorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAttentionBlock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mattention_processor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAttention\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAttnAddedKVProcessor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdual_transformer_2d\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDualTransformer2DModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/diffusers/models/attention.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_xformers_available\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mattention_processor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAttention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCombinedTimestepLabelEmbeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/diffusers/models/attention_processor.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_xformers_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mxformers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mxformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/xformers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_cpp_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m from .checkpoint import (  # noqa: E402, F401\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mget_optimal_checkpoint_policy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/xformers/checkpoint.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mSelectiveCheckpointWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mActivationWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_budget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/xformers/checkpoint.py\u001b[0m in \u001b[0;36mSelectiveCheckpointWrapper\u001b[0;34m()\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m     \u001b[0;34m@\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_policy_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/compiler/__init__.py\u001b[0m in \u001b[0;36mdisable\u001b[0;34m(fn, recursive)\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0mrecursive\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0moptional\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m \u001b[0mboolean\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0mindicating\u001b[0m \u001b[0mwhether\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdisabling\u001b[0m \u001b[0mshould\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mrecursive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \"\"\"\n\u001b[0;32m--> 228\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_dynamo/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconvert_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresume_execution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregistry\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlist_backends\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlookup_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregister_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcallback\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcallback_handler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_compile_end\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_compile_start\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mguards\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGlobalStateGuard\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_compile_pg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymbolic_convert\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTensorifyState\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_guards\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompile_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCompileContext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCompileId\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logging\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstructured\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_dynamo/symbolic_convert.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTensorifyScalarRestartAnalysis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_guards\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtracing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTracingContext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_dynamo/exc.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcounters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_dynamo/utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfft\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         )\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    335\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_sanity_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \"\"\"\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mQuick\u001b[0m \u001b[0msanity\u001b[0m \u001b[0mchecks\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcommon\u001b[0m \u001b[0mbugs\u001b[0m \u001b[0mcaused\u001b[0m \u001b[0mby\u001b[0m \u001b[0menvironment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mThere\u001b[0m \u001b[0mare\u001b[0m \u001b[0msome\u001b[0m \u001b[0mcases\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mwrong\u001b[0m \u001b[0mBLAS\u001b[0m \u001b[0mABI\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mcause\u001b[0m \u001b[0mwrong\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0munder\u001b[0m \u001b[0mspecific\u001b[0m \u001b[0mruntime\u001b[0m \u001b[0mconditions\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mare\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnecessarily\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/random/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;31m# add these for module-freeze analysis (like PyInstaller)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_common\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_bounded_integers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/random/_pickle.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmtrand\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomState\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_philox\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPhilox\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_pcg64\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPCG64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPCG64DXSM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_sfc64\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSFC64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36minit numpy.random.mtrand\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show accelerate"
      ],
      "metadata": {
        "id": "uM2YbzIBqf1q",
        "outputId": "d403603d-f349-487b-c599-d7cb6263dcc4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: accelerate\n",
            "Version: 1.7.0\n",
            "Summary: Accelerate\n",
            "Home-page: https://github.com/huggingface/accelerate\n",
            "Author: The HuggingFace team\n",
            "Author-email: zach.mueller@huggingface.co\n",
            "License: Apache\n",
            "Location: /usr/local/lib/python3.11/dist-packages\n",
            "Requires: huggingface-hub, numpy, packaging, psutil, pyyaml, safetensors, torch\n",
            "Required-by: #N/A\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q accelerate>=0.21.0"
      ],
      "metadata": {
        "id": "XoGvWOkaqZ9k",
        "outputId": "287519ae-c8f6-48a0-a16b-863d45fdde4d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Error parsing dependencies of pytorch-lightning: .* suffix can only be used with `==` or `!=` operators\n",
            "    torch (>=1.9.*)\n",
            "           ~~~~~~^\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Error parsing dependencies of torchsde: .* suffix can only be used with `==` or `!=` operators\n",
            "    numpy (>=1.19.*) ; python_version >= \"3.7\"\n",
            "           ~~~~~~~^\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y accelerate"
      ],
      "metadata": {
        "id": "negUO-T6qYPp",
        "outputId": "5bbcf3f2-8f92-48cd-8dfd-1095b6386a0e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: accelerate 0.12.0\n",
            "Uninstalling accelerate-0.12.0:\n",
            "  Successfully uninstalled accelerate-0.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q git+https://github.com/huggingface/transformers\n",
        "!pip install -q accelerate\n",
        "!pip install -q diffusers\n",
        "!pip install -q datasets\n",
        "!pip install -q torch torchvision"
      ],
      "metadata": {
        "id": "zen7kRSFpsAa",
        "outputId": "23031f52-3189-4522-8129-15e545df988c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m512.1/512.1 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m91.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33mWARNING: Error parsing dependencies of pytorch-lightning: .* suffix can only be used with `==` or `!=` operators\n",
            "    torch (>=1.9.*)\n",
            "           ~~~~~~^\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Error parsing dependencies of torchsde: .* suffix can only be used with `==` or `!=` operators\n",
            "    numpy (>=1.19.*) ; python_version >= \"3.7\"\n",
            "           ~~~~~~~^\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "peft 0.15.2 requires accelerate>=0.21.0, but you have accelerate 0.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m65.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m94.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[33mWARNING: Error parsing dependencies of pytorch-lightning: .* suffix can only be used with `==` or `!=` operators\n",
            "    torch (>=1.9.*)\n",
            "           ~~~~~~^\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Error parsing dependencies of torchsde: .* suffix can only be used with `==` or `!=` operators\n",
            "    numpy (>=1.19.*) ; python_version >= \"3.7\"\n",
            "           ~~~~~~~^\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "peft 0.15.2 requires accelerate>=0.21.0, but you have accelerate 0.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[33mWARNING: Error parsing dependencies of pytorch-lightning: .* suffix can only be used with `==` or `!=` operators\n",
            "    torch (>=1.9.*)\n",
            "           ~~~~~~^\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Error parsing dependencies of torchsde: .* suffix can only be used with `==` or `!=` operators\n",
            "    numpy (>=1.19.*) ; python_version >= \"3.7\"\n",
            "           ~~~~~~~^\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Error parsing dependencies of pytorch-lightning: .* suffix can only be used with `==` or `!=` operators\n",
            "    torch (>=1.9.*)\n",
            "           ~~~~~~^\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Error parsing dependencies of torchsde: .* suffix can only be used with `==` or `!=` operators\n",
            "    numpy (>=1.19.*) ; python_version >= \"3.7\"\n",
            "           ~~~~~~~^\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Error parsing dependencies of pytorch-lightning: .* suffix can only be used with `==` or `!=` operators\n",
            "    torch (>=1.9.*)\n",
            "           ~~~~~~^\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Error parsing dependencies of torchsde: .* suffix can only be used with `==` or `!=` operators\n",
            "    numpy (>=1.19.*) ; python_version >= \"3.7\"\n",
            "           ~~~~~~~^\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ashawkey/stable-diffusion-webui-dreambooth.git --depth 1"
      ],
      "metadata": {
        "id": "AXY7c5AEovC2",
        "outputId": "0beee62c-b87f-4cda-9b6e-8b7b36c357a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'stable-diffusion-webui-dreambooth'...\n",
            "fatal: could not read Username for 'https://github.com': No such device or address\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!accelerate launch train_dreambooth.py \\\n",
        "  --pretrained_model_name_or_path=\"runwayml/stable-diffusion-v1-5\" \\\n",
        "  --instance_data_dir=$INSTANCE_DATA_DIR \\\n",
        "  --instance_prompt=$INSTANCE_PROMPT \\\n",
        "  --output_dir=$OUTPUT_DIR \\\n",
        "  --train_batch_size=1 \\\n",
        "  --train_steps=$TRAIN_STEPS"
      ],
      "metadata": {
        "id": "1pbw751DomU4",
        "outputId": "f10dd2e0-c013-4b4d-e6b5-0493fc667eac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/bin/python3: can't open file '/content/train_dreambooth.py': [Errno 2] No such file or directory\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/accelerate\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/accelerate_cli.py\", line 43, in main\n",
            "    args.func(args)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/launch.py\", line 837, in launch_command\n",
            "    simple_launcher(args)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/launch.py\", line 354, in simple_launcher\n",
            "    raise subprocess.CalledProcessError(returncode=process.returncode, cmd=cmd)\n",
            "subprocess.CalledProcessError: Command '['/usr/bin/python3', 'train_dreambooth.py', '--pretrained_model_name_or_path=runwayml/stable-diffusion-v1-5', '--instance_data_dir=/content/data/sks-alba', '--instance_prompt=a', 'photo', 'of', 'sks-alba', 'person', '--output_dir=/content/output', '--train_batch_size=1', '--train_steps=800']' returned non-zero exit status 2.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Configura la ruta y el prompt para el entrenamiento\n",
        "INSTANCE_PROMPT = \"a photo of sks-alba person\"\n",
        "INSTANCE_DATA_DIR = \"/content/data/sks-alba\"\n",
        "OUTPUT_DIR = \"/content/output\"\n",
        "\n",
        "# Número de pasos de entrenamiento (por ejemplo, 800 pasos)\n",
        "TRAIN_STEPS = 800"
      ],
      "metadata": {
        "id": "eTNB9fGeojKv"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "A4Bae3VP6UsE",
        "outputId": "0ee3f06a-1692-496d-a7cd-99a87308d6e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0f4539bb-395e-4681-b975-f494f4d52b4e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-0f4539bb-395e-4681-b975-f494f4d52b4e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving trainer.zip to trainer (1).zip\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "cellView": "form",
        "id": "QyvcqeiL65Tj",
        "outputId": "61663959-08e3-452a-8b3d-25cf8008f3d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;32mInstalling dependencies...\n",
            "\u001b[1;32mDone, proceed\n"
          ]
        }
      ],
      "source": [
        "#@markdown # Dependencies\n",
        "\n",
        "from IPython.utils import capture\n",
        "import time\n",
        "import os\n",
        "\n",
        "print('\u001b[1;32mInstalling dependencies...')\n",
        "with capture.capture_output() as cap:\n",
        "    os.chdir('/content')\n",
        "    !pip uninstall diffusers jax -qq -y\n",
        "    !pip install -qq --no-deps accelerate==0.12.0\n",
        "    !wget -q -i https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dependencies/dbdeps.txt\n",
        "    !dpkg -i *.deb\n",
        "    !tar -C / --zstd -xf gcolabdeps.tar.zst\n",
        "    !rm *.deb | rm *.zst | rm *.txt\n",
        "    !git clone -q --depth 1 --branch main https://github.com/TheLastBen/diffusers\n",
        "    !pip install gradio==3.16.2 -qq\n",
        "    !pip install wandb==0.15.12 pydantic==1.10.2 numpy==1.24.3 -qq --no-deps\n",
        "\n",
        "    if not os.path.exists('gdrive/MyDrive/sd/libtcmalloc/libtcmalloc_minimal.so.4'):\n",
        "        %env CXXFLAGS=-std=c++14\n",
        "        !wget -q https://github.com/gperftools/gperftools/releases/download/gperftools-2.5/gperftools-2.5.tar.gz && tar zxf gperftools-2.5.tar.gz && mv gperftools-2.5 gperftools\n",
        "        !wget -q https://github.com/TheLastBen/fast-stable-diffusion/raw/main/AUTOMATIC1111_files/Patch\n",
        "        %cd /content/gperftools\n",
        "        !patch -p1 < /content/Patch\n",
        "        !./configure --enable-minimal --enable-libunwind --enable-frame-pointers --enable-dynamic-sized-delete-support --enable-sized-delete --enable-emergency-malloc; make -j4\n",
        "        !mkdir -p /content/gdrive/MyDrive/sd/libtcmalloc && cp .libs/libtcmalloc*.so* /content/gdrive/MyDrive/sd/libtcmalloc\n",
        "        %env LD_PRELOAD=/content/gdrive/MyDrive/sd/libtcmalloc/libtcmalloc_minimal.so.4\n",
        "        %cd /content\n",
        "        !rm *.tar.gz Patch && rm -r /content/gperftools\n",
        "    else:\n",
        "        %env LD_PRELOAD=/content/gdrive/MyDrive/sd/libtcmalloc/libtcmalloc_minimal.so.4\n",
        "\n",
        "    os.environ['PYTHONWARNINGS'] = 'ignore'\n",
        "    !sed -i 's@text = _formatwarnmsg(msg)@text =\\\"\\\"@g' /usr/lib/python3.11/warnings.py\n",
        "    !sed -i 's@HfFolder, cached_download@HfFolder@g' /usr/local/lib/python3.11/dist-packages/diffusers/utils/dynamic_modules_utils.py\n",
        "    !sed -i 's@from pytorch_lightning.loggers.wandb import WandbLogger  # noqa: F401@@g' /usr/local/lib/python3.11/dist-packages/pytorch_lightning/loggers/__init__.py\n",
        "    !sed -i 's@from .mailbox import ContextCancelledError@@g' /usr/local/lib/python3.11/dist-packages/wandb/sdk/lib/retry.py\n",
        "    !sed -i 's@raise ContextCancelledError(\"retry timeout\")@print(\"retry timeout\")@g' /usr/local/lib/python3.11/dist-packages/wandb/sdk/lib/retry.py\n",
        "    !rm -r /usr/local/lib/python3.11/dist-packages/tensorflow*\n",
        "\n",
        "print('\u001b[1;32mDone, proceed')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3SsbIlxw66N"
      },
      "source": [
        "# Model Download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "O3KHGKqyeJp9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "from IPython.utils import capture\n",
        "from IPython.display import clear_output\n",
        "import wget\n",
        "from subprocess import check_output\n",
        "import urllib.request\n",
        "import requests\n",
        "import base64\n",
        "from gdown.download import get_url_from_gdrive_confirmation\n",
        "from urllib.parse import urlparse, parse_qs, unquote\n",
        "from urllib.request import urlopen, Request\n",
        "import re\n",
        "\n",
        "def getsrc(url):\n",
        "    parsed_url = urlparse(url)\n",
        "    if parsed_url.netloc == 'civitai.com':\n",
        "        src='civitai'\n",
        "    elif parsed_url.netloc == 'drive.google.com':\n",
        "        src='gdrive'\n",
        "    elif parsed_url.netloc == 'huggingface.co':\n",
        "        src='huggingface'\n",
        "    else:\n",
        "        src='others'\n",
        "    return src\n",
        "\n",
        "\n",
        "\n",
        "def get_name(url, gdrive):\n",
        "    if not gdrive:\n",
        "        response = requests.get(url, allow_redirects=False)\n",
        "        if \"Location\" in response.headers:\n",
        "            redirected_url = response.headers[\"Location\"]\n",
        "            quer = parse_qs(urlparse(redirected_url).query)\n",
        "            if \"response-content-disposition\" in quer:\n",
        "                disp_val = quer[\"response-content-disposition\"][0].split(\";\")\n",
        "                for vals in disp_val:\n",
        "                    if vals.strip().startswith(\"filename=\"):\n",
        "                        filenm=unquote(vals.split(\"=\", 1)[1].strip())\n",
        "                        return filenm.replace(\"\\\"\",\"\")\n",
        "    else:\n",
        "        headers = {\"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36\"}\n",
        "        lnk=\"https://drive.google.com/uc?id={id}&export=download\".format(id=url[url.find(\"/d/\")+3:url.find(\"/view\")])\n",
        "        res = requests.session().get(lnk, headers=headers, stream=True, verify=True)\n",
        "        res = requests.session().get(get_url_from_gdrive_confirmation(res.text), headers=headers, stream=True, verify=True)\n",
        "        content_disposition = six.moves.urllib_parse.unquote(res.headers[\"Content-Disposition\"])\n",
        "        filenm = re.search('attachment; filename=\"(.*?)\"', content_disposition).groups()[0]\n",
        "        return filenm\n",
        "\n",
        "#@markdown - Skip this cell if you are loading a previous session that contains a trained model.\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "Model_Version = \"1.5\" #@param [ \"1.5\", \"V2.1-512px\", \"V2.1-768px\"]\n",
        "\n",
        "#@markdown - Choose which version to finetune.\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "  os.chdir('/content')\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "Path_to_HuggingFace= \"\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown - Load and finetune a model from Hugging Face, use the format \"profile/model\" like : runwayml/stable-diffusion-v1-5\n",
        "#@markdown - If the custom model is private or requires a token, create token.txt containing the token in \"Fast-Dreambooth\" folder in your gdrive.\n",
        "\n",
        "MODEL_PATH = \"\" #@param {type:\"string\"}\n",
        "\n",
        "MODEL_LINK = \"\" #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "if os.path.exists('/content/gdrive/MyDrive/Fast-Dreambooth/token.txt'):\n",
        "  with open(\"/content/gdrive/MyDrive/Fast-Dreambooth/token.txt\") as f:\n",
        "     token = f.read()\n",
        "  authe=f'https://USER:{token}@'\n",
        "else:\n",
        "  authe=\"https://\"\n",
        "\n",
        "def downloadmodel():\n",
        "\n",
        "  if os.path.exists('/content/stable-diffusion-v1-5'):\n",
        "    !rm -r /content/stable-diffusion-v1-5\n",
        "  clear_output()\n",
        "\n",
        "  os.chdir('/content')\n",
        "\n",
        "\n",
        "  print(\"\u001b[1;32mDownloading the model...\")\n",
        "  !wget -q \"https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/v1-5-pruned-emaonly.safetensors\" -O model.safetensors\n",
        "\n",
        "  if os.path.exists('/content/model.safetensors'):\n",
        "      !wget -q -O config.yaml https://github.com/CompVis/stable-diffusion/raw/main/configs/stable-diffusion/v1-inference.yaml\n",
        "      clear_output()\n",
        "      !python /content/diffusers/scripts/convert_original_stable_diffusion_to_diffusers.py --checkpoint_path /content/model.safetensors --dump_path /content/stable-diffusion-v1-5 --original_config_file config.yaml --from_safetensors\n",
        "      !rm config.yaml\n",
        "      clear_output()\n",
        "      os.chdir('/content/stable-diffusion-v1-5')\n",
        "      !wget -q -O vae/diffusion_pytorch_model.bin https://huggingface.co/stabilityai/sd-vae-ft-mse/resolve/main/diffusion_pytorch_model.bin\n",
        "      !rm model_index.json\n",
        "      clear_output()\n",
        "      time.sleep(1)\n",
        "      wget.download('https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dreambooth/model_index.json')\n",
        "      os.chdir('/content')\n",
        "\n",
        "\n",
        "def newdownloadmodel():\n",
        "\n",
        "  os.chdir('/content')\n",
        "  clear_output()\n",
        "  !mkdir /content/stable-diffusion-v2-768\n",
        "  os.chdir('/content/stable-diffusion-v2-768')\n",
        "  !git config --global init.defaultBranch main\n",
        "  !git init\n",
        "  !git lfs install --system --skip-repo\n",
        "  !git remote add -f origin  \"https://huggingface.co/stabilityai/stable-diffusion-2-1\"\n",
        "  !git config core.sparsecheckout true\n",
        "  !echo -e \"scheduler\\ntext_encoder\\ntokenizer\\nunet\\nvae\\nfeature_extractor\\nmodel_index.json\\n!*.safetensors\\n!*.fp16.bin\" > .git/info/sparse-checkout\n",
        "  !git pull origin main\n",
        "  !rm -r /content/stable-diffusion-v2-768/.git\n",
        "  os.chdir('/content')\n",
        "  clear_output()\n",
        "  print('\u001b[1;32mDONE !')\n",
        "\n",
        "\n",
        "def newdownloadmodelb():\n",
        "\n",
        "  os.chdir('/content')\n",
        "  clear_output()\n",
        "  !mkdir /content/stable-diffusion-v2-512\n",
        "  os.chdir('/content/stable-diffusion-v2-512')\n",
        "  !git config --global init.defaultBranch main\n",
        "  !git init\n",
        "  !git lfs install --system --skip-repo\n",
        "  !git remote add -f origin  \"https://huggingface.co/stabilityai/stable-diffusion-2-1-base\"\n",
        "  !git config core.sparsecheckout true\n",
        "  !echo -e \"scheduler\\ntext_encoder\\ntokenizer\\nunet\\nvae\\nfeature_extractor\\nmodel_index.json\\n!*.safetensors\\n!*.fp16.bin\" > .git/info/sparse-checkout\n",
        "  !git pull origin main\n",
        "  !rm -r /content/stable-diffusion-v2-512/.git\n",
        "  os.chdir('/content')\n",
        "  clear_output()\n",
        "  print('\u001b[1;32mDONE !')\n",
        "\n",
        "\n",
        "if Path_to_HuggingFace != \"\":\n",
        "  if authe==\"https://\":\n",
        "    textenc= f\"{authe}huggingface.co/{Path_to_HuggingFace}/resolve/main/text_encoder/pytorch_model.bin\"\n",
        "    txtenc_size=urllib.request.urlopen(textenc).info().get('Content-Length', None)\n",
        "  else:\n",
        "    textenc= f\"https://huggingface.co/{Path_to_HuggingFace}/resolve/main/text_encoder/pytorch_model.bin\"\n",
        "    req=urllib.request.Request(textenc)\n",
        "    req.add_header('Authorization', f'Bearer {token}')\n",
        "    txtenc_size=urllib.request.urlopen(req).info().get('Content-Length', None)\n",
        "  if int(txtenc_size)> 670000000 :\n",
        "    if os.path.exists('/content/stable-diffusion-custom'):\n",
        "      !rm -r /content/stable-diffusion-custom\n",
        "    clear_output()\n",
        "    os.chdir('/content')\n",
        "    clear_output()\n",
        "    print(\"\u001b[1;32mV2\")\n",
        "    !mkdir /content/stable-diffusion-custom\n",
        "    os.chdir('/content/stable-diffusion-custom')\n",
        "    !git config --global init.defaultBranch main\n",
        "    !git init\n",
        "    !git lfs install --system --skip-repo\n",
        "    !git remote add -f origin  \"{authe}huggingface.co/{Path_to_HuggingFace}\"\n",
        "    !git config core.sparsecheckout true\n",
        "    !echo -e \"scheduler\\ntext_encoder\\ntokenizer\\nunet\\nvae\\nfeature_extractor\\nmodel_index.json\\n!*.safetensors\" > .git/info/sparse-checkout\n",
        "    !git pull origin main\n",
        "    if os.path.exists('/content/stable-diffusion-custom/unet/diffusion_pytorch_model.bin'):\n",
        "      !rm -r /content/stable-diffusion-custom/.git\n",
        "      os.chdir('/content')\n",
        "      MODEL_NAME=\"/content/stable-diffusion-custom\"\n",
        "      clear_output()\n",
        "      print('\u001b[1;32mDONE !')\n",
        "    else:\n",
        "      while not os.path.exists('/content/stable-diffusion-custom/unet/diffusion_pytorch_model.bin'):\n",
        "            print('\u001b[1;31mCheck the link you provided')\n",
        "            time.sleep(5)\n",
        "  else:\n",
        "    if os.path.exists('/content/stable-diffusion-custom'):\n",
        "      !rm -r /content/stable-diffusion-custom\n",
        "    clear_output()\n",
        "    os.chdir('/content')\n",
        "    clear_output()\n",
        "    print(\"\u001b[1;32mV1\")\n",
        "    !mkdir /content/stable-diffusion-custom\n",
        "    os.chdir('/content/stable-diffusion-custom')\n",
        "    !git init\n",
        "    !git lfs install --system --skip-repo\n",
        "    !git remote add -f origin  \"{authe}huggingface.co/{Path_to_HuggingFace}\"\n",
        "    !git config core.sparsecheckout true\n",
        "    !echo -e \"scheduler\\ntext_encoder\\ntokenizer\\nunet\\nvae\\nmodel_index.json\\n!*.safetensors\" > .git/info/sparse-checkout\n",
        "    !git pull origin main\n",
        "    if os.path.exists('/content/stable-diffusion-custom/unet/diffusion_pytorch_model.bin'):\n",
        "      !rm -r /content/stable-diffusion-custom/.git\n",
        "      !rm model_index.json\n",
        "      time.sleep(1)\n",
        "      wget.download('https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dreambooth/model_index.json')\n",
        "      os.chdir('/content')\n",
        "      MODEL_NAME=\"/content/stable-diffusion-custom\"\n",
        "      clear_output()\n",
        "      print('\u001b[1;32mDONE !')\n",
        "    else:\n",
        "      while not os.path.exists('/content/stable-diffusion-custom/unet/diffusion_pytorch_model.bin'):\n",
        "            print('\u001b[1;31mCheck the link you provided')\n",
        "            time.sleep(5)\n",
        "\n",
        "elif MODEL_PATH !=\"\":\n",
        "\n",
        "  modelname=os.path.basename(MODEL_PATH)\n",
        "  sftnsr=\"\"\n",
        "  if modelname.split('.')[-1]=='safetensors':\n",
        "    sftnsr=\"--from_safetensors\"\n",
        "\n",
        "  %cd /content\n",
        "  clear_output()\n",
        "  if os.path.exists(str(MODEL_PATH)):\n",
        "    wget.download('https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/det.py')\n",
        "    print('\u001b[1;33mDetecting model version...')\n",
        "    Custom_Model_Version=check_output('python det.py '+sftnsr+' --MODEL_PATH '+str(MODEL_PATH), shell=True).decode('utf-8').replace('\\n', '')\n",
        "    clear_output()\n",
        "    print('\u001b[1;32m'+Custom_Model_Version+' Detected')\n",
        "    !rm det.py\n",
        "    if Custom_Model_Version=='1.5':\n",
        "      !wget -q -O config.yaml https://github.com/CompVis/stable-diffusion/raw/main/configs/stable-diffusion/v1-inference.yaml\n",
        "      !python /content/diffusers/scripts/convert_original_stable_diffusion_to_diffusers.py --checkpoint_path \"$MODEL_PATH\" --dump_path stable-diffusion-custom --original_config_file config.yaml $sftnsr\n",
        "      !rm /content/config.yaml\n",
        "\n",
        "    elif Custom_Model_Version=='V2.1-512px':\n",
        "      !wget -q -O convertodiff.py https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dreambooth/convertodiffv2.py\n",
        "      !python /content/convertodiff.py \"$MODEL_PATH\" /content/stable-diffusion-custom --v2 --reference_model stabilityai/stable-diffusion-2-1-base $sftnsr\n",
        "      !rm /content/convertodiff.py\n",
        "\n",
        "    elif Custom_Model_Version=='V2.1-768px':\n",
        "      !wget -q -O convertodiff.py https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/convertodiffv2-768.py\n",
        "      !python /content/convertodiff.py \"$MODEL_PATH\" /content/stable-diffusion-custom --v2 --reference_model stabilityai/stable-diffusion-2-1 $sftnsr\n",
        "      !rm /content/convertodiff.py\n",
        "\n",
        "\n",
        "    if os.path.exists('/content/stable-diffusion-custom/unet/diffusion_pytorch_model.bin'):\n",
        "      clear_output()\n",
        "      MODEL_NAME=\"/content/stable-diffusion-custom\"\n",
        "      print('\u001b[1;32mDONE !')\n",
        "    else:\n",
        "      !rm -r /content/stable-diffusion-custom\n",
        "      while not os.path.exists('/content/stable-diffusion-custom/unet/diffusion_pytorch_model.bin'):\n",
        "        print('\u001b[1;31mConversion error')\n",
        "        time.sleep(5)\n",
        "  else:\n",
        "    while not os.path.exists(str(MODEL_PATH)):\n",
        "       print('\u001b[1;31mWrong path, use the colab file explorer to copy the path')\n",
        "       time.sleep(5)\n",
        "\n",
        "elif MODEL_LINK !=\"\":\n",
        "    os.chdir('/content')\n",
        "\n",
        "    src=getsrc(MODEL_LINK)\n",
        "\n",
        "    if src=='civitai':\n",
        "       modelname=get_name(str(MODEL_LINK), False)\n",
        "    elif src=='gdrive':\n",
        "       modelname=get_name(str(MODEL_LINK), True)\n",
        "    else:\n",
        "       modelname=os.path.basename(str(MODEL_LINK))\n",
        "\n",
        "    sftnsr=\"\"\n",
        "    if modelname.split('.')[-1]!='safetensors':\n",
        "      modelnm=\"model.ckpt\"\n",
        "    else:\n",
        "      modelnm=\"model.safetensors\"\n",
        "      sftnsr=\"--from_safetensors\"\n",
        "\n",
        "    !gdown --fuzzy \"$MODEL_LINK\" -O $modelnm\n",
        "\n",
        "    if os.path.exists(modelnm):\n",
        "      if os.path.getsize(modelnm) > 1810671599:\n",
        "        wget.download('https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/det.py')\n",
        "        print('\u001b[1;33mDetecting model version...')\n",
        "        Custom_Model_Version=check_output('python det.py '+sftnsr+' --MODEL_PATH '+modelnm, shell=True).decode('utf-8').replace('\\n', '')\n",
        "        clear_output()\n",
        "        print('\u001b[1;32m'+Custom_Model_Version+' Detected')\n",
        "        !rm det.py\n",
        "        if Custom_Model_Version=='1.5':\n",
        "          !wget -q -O config.yaml https://github.com/CompVis/stable-diffusion/raw/main/configs/stable-diffusion/v1-inference.yaml\n",
        "          !python /content/diffusers/scripts/convert_original_stable_diffusion_to_diffusers.py --checkpoint_path $modelnm --dump_path stable-diffusion-custom --original_config_file config.yaml $sftnsr\n",
        "          !rm config.yaml\n",
        "\n",
        "        elif Custom_Model_Version=='V2.1-512px':\n",
        "          !wget -q -O convertodiff.py https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dreambooth/convertodiffv2.py\n",
        "          !python /content/convertodiff.py $modelnm /content/stable-diffusion-custom --v2 --reference_model stabilityai/stable-diffusion-2-1-base $sftnsr\n",
        "          !rm convertodiff.py\n",
        "\n",
        "        elif Custom_Model_Version=='V2.1-768px':\n",
        "          !wget -q -O convertodiff.py https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/convertodiffv2-768.py\n",
        "          !python /content/convertodiff.py $modelnm /content/stable-diffusion-custom --v2 --reference_model stabilityai/stable-diffusion-2-1 $sftnsr\n",
        "          !rm convertodiff.py\n",
        "\n",
        "\n",
        "        if os.path.exists('/content/stable-diffusion-custom/unet/diffusion_pytorch_model.bin'):\n",
        "          clear_output()\n",
        "          MODEL_NAME=\"/content/stable-diffusion-custom\"\n",
        "          print('\u001b[1;32mDONE !')\n",
        "        else:\n",
        "          !rm -r stable-diffusion-custom\n",
        "          !rm $modelnm\n",
        "          while not os.path.exists('/content/stable-diffusion-custom/unet/diffusion_pytorch_model.bin'):\n",
        "            print('\u001b[1;31mConversion error')\n",
        "            time.sleep(5)\n",
        "      else:\n",
        "        while os.path.getsize(modelnm) < 1810671599:\n",
        "           print('\u001b[1;31mWrong link, check that the link is valid')\n",
        "           time.sleep(5)\n",
        "\n",
        "else:\n",
        "  if Model_Version==\"1.5\":\n",
        "    if not os.path.exists('/content/stable-diffusion-v1-5/unet'):\n",
        "      downloadmodel()\n",
        "      MODEL_NAME=\"/content/stable-diffusion-v1-5\"\n",
        "      print(\"\u001b[1;32mv1.5 model downloaded\")\n",
        "    else:\n",
        "      MODEL_NAME=\"/content/stable-diffusion-v1-5\"\n",
        "      print(\"\u001b[1;32mThe v1.5 model already exists, using this model.\")\n",
        "  elif Model_Version==\"V2.1-512px\":\n",
        "    if not os.path.exists('/content/stable-diffusion-v2-512'):\n",
        "      newdownloadmodelb()\n",
        "      MODEL_NAME=\"/content/stable-diffusion-v2-512\"\n",
        "    else:\n",
        "      MODEL_NAME=\"/content/stable-diffusion-v2-512\"\n",
        "      print(\"\u001b[1;32mThe v2-512px model already exists, using this model.\")\n",
        "  elif Model_Version==\"V2.1-768px\":\n",
        "    if not os.path.exists('/content/stable-diffusion-v2-768'):\n",
        "      newdownloadmodel()\n",
        "      MODEL_NAME=\"/content/stable-diffusion-v2-768\"\n",
        "    else:\n",
        "      MODEL_NAME=\"/content/stable-diffusion-v2-768\"\n",
        "      print(\"\u001b[1;32mThe v2-768px model already exists, using this model.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tN76Cj5P3RL"
      },
      "source": [
        "# Dreambooth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "A1B299g-_VJo"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from IPython.display import clear_output\n",
        "from IPython.utils import capture\n",
        "from os import listdir\n",
        "from os.path import isfile\n",
        "from subprocess import check_output\n",
        "import wget\n",
        "import time\n",
        "\n",
        "#@markdown #Create/Load a Session\n",
        "\n",
        "try:\n",
        "  MODEL_NAME\n",
        "  pass\n",
        "except:\n",
        "  MODEL_NAME=\"\"\n",
        "\n",
        "PT=\"\"\n",
        "\n",
        "Session_Name = \"\" #@param{type: 'string'}\n",
        "while Session_Name==\"\":\n",
        "  print('\u001b[1;31mInput the Session Name:')\n",
        "  Session_Name=input('')\n",
        "Session_Name=Session_Name.replace(\" \",\"_\")\n",
        "\n",
        "#@markdown - Enter the session name, it if it exists, it will load it, otherwise it'll create an new session.\n",
        "\n",
        "Session_Link_optional = \"\" #@param{type: 'string'}\n",
        "\n",
        "#@markdown - Import a session from another gdrive, the shared gdrive link must point to the specific session's folder that contains the trained CKPT, remove any intermediary CKPT if any.\n",
        "\n",
        "WORKSPACE='/content/gdrive/MyDrive/Fast-Dreambooth'\n",
        "\n",
        "if Session_Link_optional !=\"\":\n",
        "  print('\u001b[1;32mDownloading session...')\n",
        "  with capture.capture_output() as cap:\n",
        "    %cd /content\n",
        "    if not os.path.exists(str(WORKSPACE+'/Sessions')):\n",
        "      %mkdir -p $WORKSPACE'/Sessions'\n",
        "      time.sleep(1)\n",
        "    %cd $WORKSPACE'/Sessions'\n",
        "    !gdown --folder --remaining-ok -O $Session_Name  $Session_Link_optional\n",
        "    %cd $Session_Name\n",
        "    !rm -r instance_images\n",
        "    !unzip instance_images.zip\n",
        "    !rm -r captions\n",
        "    !unzip captions.zip\n",
        "    %cd /content\n",
        "\n",
        "\n",
        "INSTANCE_NAME=Session_Name\n",
        "OUTPUT_DIR=\"/content/models/\"+Session_Name\n",
        "SESSION_DIR=WORKSPACE+'/Sessions/'+Session_Name\n",
        "INSTANCE_DIR=SESSION_DIR+'/instance_images'\n",
        "CAPTIONS_DIR=SESSION_DIR+'/captions'\n",
        "MDLPTH=str(SESSION_DIR+\"/\"+Session_Name+'.ckpt')\n",
        "\n",
        "if os.path.exists(str(SESSION_DIR)):\n",
        "  mdls=[ckpt for ckpt in listdir(SESSION_DIR) if ckpt.split(\".\")[-1]==\"ckpt\"]\n",
        "  if not os.path.exists(MDLPTH) and '.ckpt' in str(mdls):\n",
        "\n",
        "    def f(n):\n",
        "      k=0\n",
        "      for i in mdls:\n",
        "        if k==n:\n",
        "          !mv \"$SESSION_DIR/$i\" $MDLPTH\n",
        "        k=k+1\n",
        "\n",
        "    k=0\n",
        "    print('\u001b[1;33mNo final checkpoint model found, select which intermediary checkpoint to use, enter only the number, (000 to skip):\\n\u001b[1;34m')\n",
        "\n",
        "    for i in mdls:\n",
        "      print(str(k)+'- '+i)\n",
        "      k=k+1\n",
        "    n=input()\n",
        "    while int(n)>k-1:\n",
        "      n=input()\n",
        "    if n!=\"000\":\n",
        "      f(int(n))\n",
        "      print('\u001b[1;32mUsing the model '+ mdls[int(n)]+\" ...\")\n",
        "      time.sleep(2)\n",
        "    else:\n",
        "      print('\u001b[1;32mSkipping the intermediary checkpoints.')\n",
        "    del n\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "  %cd /content\n",
        "  resume=False\n",
        "\n",
        "if os.path.exists(str(SESSION_DIR)) and not os.path.exists(MDLPTH):\n",
        "  print('\u001b[1;32mLoading session with no previous model, using the original model or the custom downloaded model')\n",
        "  if MODEL_NAME==\"\":\n",
        "    print('\u001b[1;31mNo model found, use the \"Model Download\" cell to download a model.')\n",
        "  else:\n",
        "    print('\u001b[1;32mSession Loaded, proceed to uploading instance images')\n",
        "\n",
        "elif os.path.exists(MDLPTH):\n",
        "  print('\u001b[1;32mSession found, loading the trained model ...')\n",
        "  wget.download('https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/det.py')\n",
        "  print('\u001b[1;33mDetecting model version...')\n",
        "  Model_Version=check_output('python det.py --MODEL_PATH '+MDLPTH, shell=True).decode('utf-8').replace('\\n', '')\n",
        "  clear_output()\n",
        "  print('\u001b[1;32m'+Model_Version+' Detected')\n",
        "  !rm det.py\n",
        "  if Model_Version=='1.5':\n",
        "    !wget -q -O config.yaml https://github.com/CompVis/stable-diffusion/raw/main/configs/stable-diffusion/v1-inference.yaml\n",
        "    print('\u001b[1;32mSession found, loading the trained model ...')\n",
        "    !python /content/diffusers/scripts/convert_original_stable_diffusion_to_diffusers.py --checkpoint_path $MDLPTH --dump_path \"$OUTPUT_DIR\" --original_config_file config.yaml\n",
        "    !rm /content/config.yaml\n",
        "\n",
        "  elif Model_Version=='V2.1-512px':\n",
        "    !wget -q -O convertodiff.py https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dreambooth/convertodiffv2.py\n",
        "    print('\u001b[1;32mSession found, loading the trained model ...')\n",
        "    !python /content/convertodiff.py \"$MDLPTH\" \"$OUTPUT_DIR\" --v2 --reference_model stabilityai/stable-diffusion-2-1-base\n",
        "    !rm /content/convertodiff.py\n",
        "\n",
        "  elif Model_Version=='V2.1-768px':\n",
        "    !wget -q -O convertodiff.py https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/convertodiffv2-768.py\n",
        "    print('\u001b[1;32mSession found, loading the trained model ...')\n",
        "    !python /content/convertodiff.py \"$MDLPTH\" \"$OUTPUT_DIR\" --v2 --reference_model stabilityai/stable-diffusion-2-1\n",
        "    !rm /content/convertodiff.py\n",
        "\n",
        "\n",
        "  if os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n",
        "    resume=True\n",
        "    clear_output()\n",
        "    print('\u001b[1;32mSession loaded.')\n",
        "  else:\n",
        "    if not os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n",
        "      print('\u001b[1;31mConversion error, if the error persists, remove the CKPT file from the current session folder')\n",
        "\n",
        "elif not os.path.exists(str(SESSION_DIR)):\n",
        "    %mkdir -p \"$INSTANCE_DIR\"\n",
        "    print('\u001b[1;32mCreating session...')\n",
        "    if MODEL_NAME==\"\":\n",
        "      print('\u001b[1;31mNo model found, use the \"Model Download\" cell to download a model.')\n",
        "    else:\n",
        "      print('\u001b[1;32mSession created, proceed to uploading instance images')\n",
        "\n",
        "    #@markdown\n",
        "\n",
        "    #@markdown # The most important step is to rename the instance pictures of each subject to a unique unknown identifier, example :\n",
        "    #@markdown - If you have 10 pictures of yourself, simply select them all and rename only one to the chosen identifier for example : phtmejhn, the files would be : phtmejhn (1).jpg, phtmejhn (2).png ....etc then upload them, do the same for other people or objects with a different identifier, and that's it.\n",
        "    #@markdown - Checkout this example : https://i.imgur.com/d2lD3rz.jpeg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "LC4ukG60fgMy"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "from google.colab import files\n",
        "import time\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import ipywidgets as widgets\n",
        "from io import BytesIO\n",
        "import wget\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "  %cd /content\n",
        "  if not os.path.exists(\"/content/smart_crop.py\"):\n",
        "    wget.download('https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dreambooth/smart_crop.py')\n",
        "  from smart_crop import *\n",
        "\n",
        "#@markdown #Instance Images\n",
        "#@markdown ----\n",
        "\n",
        "#@markdown\n",
        "#@markdown - Run the cell to upload the instance pictures.\n",
        "#@markdown - You can add `external captions` in txt files by simply giving each txt file the same name as the instance image, for example dikgur (1).jpg and dikgur (1).txt, and upload them here, to use the external captions, check the box \"external_captions\" in the training cell. `All the images must have one same extension` jpg or png or....etc\n",
        "\n",
        "Remove_existing_instance_images= True #@param{type: 'boolean'}\n",
        "#@markdown - Uncheck the box to keep the existing instance images.\n",
        "\n",
        "if Remove_existing_instance_images:\n",
        "  if os.path.exists(str(INSTANCE_DIR)):\n",
        "    !rm -r \"$INSTANCE_DIR\"\n",
        "  if os.path.exists(str(CAPTIONS_DIR)):\n",
        "    !rm -r \"$CAPTIONS_DIR\"\n",
        "\n",
        "if not os.path.exists(str(INSTANCE_DIR)):\n",
        "  %mkdir -p \"$INSTANCE_DIR\"\n",
        "if not os.path.exists(str(CAPTIONS_DIR)):\n",
        "  %mkdir -p \"$CAPTIONS_DIR\"\n",
        "\n",
        "if os.path.exists(INSTANCE_DIR+\"/.ipynb_checkpoints\"):\n",
        "  %rm -r $INSTANCE_DIR\"/.ipynb_checkpoints\"\n",
        "\n",
        "\n",
        "IMAGES_FOLDER_OPTIONAL=\"\" #@param{type: 'string'}\n",
        "\n",
        "#@markdown - If you prefer to specify directly the folder of the pictures instead of uploading, this will add the pictures to the existing (if any) instance images. Leave EMPTY to upload.\n",
        "\n",
        "Smart_Crop_images= True #@param{type: 'boolean'}\n",
        "Crop_size = 512 #@param [\"512\", \"576\", \"640\", \"704\", \"768\", \"832\", \"896\", \"960\", \"1024\"] {type:\"raw\"}\n",
        "\n",
        "#@markdown - Smart crop the images without manual intervention.\n",
        "\n",
        "while IMAGES_FOLDER_OPTIONAL !=\"\" and not os.path.exists(str(IMAGES_FOLDER_OPTIONAL)):\n",
        "  print('\u001b[1;31mThe image folder specified does not exist, use the colab file explorer to copy the path :')\n",
        "  IMAGES_FOLDER_OPTIONAL=input('')\n",
        "\n",
        "if IMAGES_FOLDER_OPTIONAL!=\"\":\n",
        "  if os.path.exists(IMAGES_FOLDER_OPTIONAL+\"/.ipynb_checkpoints\"):\n",
        "    %rm -r \"$IMAGES_FOLDER_OPTIONAL\"\"/.ipynb_checkpoints\"\n",
        "\n",
        "  with capture.capture_output() as cap:\n",
        "    !mv $IMAGES_FOLDER_OPTIONAL/*.txt $CAPTIONS_DIR\n",
        "  if Smart_Crop_images:\n",
        "    for filename in tqdm(os.listdir(IMAGES_FOLDER_OPTIONAL), bar_format='  |{bar:15}| {n_fmt}/{total_fmt} Uploaded'):\n",
        "      extension = filename.split(\".\")[-1]\n",
        "      identifier=filename.split(\".\")[0]\n",
        "      new_path_with_file = os.path.join(INSTANCE_DIR, filename)\n",
        "      file = Image.open(IMAGES_FOLDER_OPTIONAL+\"/\"+filename)\n",
        "      width, height = file.size\n",
        "      if file.size !=(Crop_size, Crop_size):\n",
        "        image=crop_image(file, Crop_size)\n",
        "        if extension.upper()==\"JPG\" or extension.upper()==\"jpg\":\n",
        "            image[0] = image[0].convert(\"RGB\")\n",
        "            image[0].save(new_path_with_file, format=\"JPEG\", quality = 100)\n",
        "        else:\n",
        "            image[0].save(new_path_with_file, format=extension.upper())\n",
        "      else:\n",
        "        !cp \"$IMAGES_FOLDER_OPTIONAL/$filename\" \"$INSTANCE_DIR\"\n",
        "\n",
        "  else:\n",
        "    for filename in tqdm(os.listdir(IMAGES_FOLDER_OPTIONAL), bar_format='  |{bar:15}| {n_fmt}/{total_fmt} Uploaded'):\n",
        "      %cp -r \"$IMAGES_FOLDER_OPTIONAL/$filename\" \"$INSTANCE_DIR\"\n",
        "\n",
        "  print('\\n\u001b[1;32mDone, proceed to the next cell')\n",
        "\n",
        "\n",
        "elif IMAGES_FOLDER_OPTIONAL ==\"\":\n",
        "  up=\"\"\n",
        "  uploaded = files.upload()\n",
        "  for filename in uploaded.keys():\n",
        "    if filename.split(\".\")[-1]==\"txt\":\n",
        "      shutil.move(filename, CAPTIONS_DIR)\n",
        "    up=[filename for filename in uploaded.keys() if filename.split(\".\")[-1]!=\"txt\"]\n",
        "  if Smart_Crop_images:\n",
        "    for filename in tqdm(up, bar_format='  |{bar:15}| {n_fmt}/{total_fmt} Uploaded'):\n",
        "      shutil.move(filename, INSTANCE_DIR)\n",
        "      extension = filename.split(\".\")[-1]\n",
        "      identifier=filename.split(\".\")[0]\n",
        "      new_path_with_file = os.path.join(INSTANCE_DIR, filename)\n",
        "      file = Image.open(new_path_with_file)\n",
        "      width, height = file.size\n",
        "      if file.size !=(Crop_size, Crop_size):\n",
        "        image=crop_image(file, Crop_size)\n",
        "        if extension.upper()==\"JPG\" or extension.upper()==\"jpg\":\n",
        "            image[0] = image[0].convert(\"RGB\")\n",
        "            image[0].save(new_path_with_file, format=\"JPEG\", quality = 100)\n",
        "        else:\n",
        "            image[0].save(new_path_with_file, format=extension.upper())\n",
        "      clear_output()\n",
        "  else:\n",
        "    for filename in tqdm(uploaded.keys(), bar_format='  |{bar:15}| {n_fmt}/{total_fmt} Uploaded'):\n",
        "      shutil.move(filename, INSTANCE_DIR)\n",
        "      clear_output()\n",
        "  print('\\n\u001b[1;32mDone, proceed to the next cell')\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "  %cd \"$INSTANCE_DIR\"\n",
        "  !find . -name \"* *\" -type f | rename 's/ /-/g'\n",
        "  %cd \"$CAPTIONS_DIR\"\n",
        "  !find . -name \"* *\" -type f | rename 's/ /-/g'\n",
        "\n",
        "  %cd $SESSION_DIR\n",
        "  !rm instance_images.zip captions.zip\n",
        "  !zip -r instance_images instance_images\n",
        "  !zip -r captions captions\n",
        "  %cd /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Baw78R-w4T2j"
      },
      "outputs": [],
      "source": [
        "import ipywidgets as widgets\n",
        "from io import BytesIO\n",
        "#@markdown #Captions (optional)\n",
        "\n",
        "#@markdown - Open a tool to manually `create` captions or edit existing captions of the instance images, do not use captions when training on a face.\n",
        "\n",
        "paths=\"\"\n",
        "out=\"\"\n",
        "widgets_l=\"\"\n",
        "clear_output()\n",
        "def Caption(path):\n",
        "    if path!=\"Select an instance image to caption\":\n",
        "\n",
        "      name = os.path.splitext(os.path.basename(path))[0]\n",
        "      ext=os.path.splitext(os.path.basename(path))[-1][1:]\n",
        "      if ext==\"jpg\" or \"JPG\":\n",
        "        ext=\"JPEG\"\n",
        "\n",
        "      if os.path.exists(CAPTIONS_DIR+\"/\"+name + '.txt'):\n",
        "        with open(CAPTIONS_DIR+\"/\"+name + '.txt', 'r') as f:\n",
        "            text = f.read()\n",
        "      else:\n",
        "        with open(CAPTIONS_DIR+\"/\"+name + '.txt', 'w') as f:\n",
        "            f.write(\"\")\n",
        "            with open(CAPTIONS_DIR+\"/\"+name + '.txt', 'r') as f:\n",
        "                text = f.read()\n",
        "\n",
        "      img=Image.open(os.path.join(INSTANCE_DIR,path))\n",
        "      img=img.convert(\"RGB\")\n",
        "      img=img.resize((420, 420))\n",
        "      image_bytes = BytesIO()\n",
        "      img.save(image_bytes, format=ext, qualiy=10)\n",
        "      image_bytes.seek(0)\n",
        "      image_data = image_bytes.read()\n",
        "      img= image_data\n",
        "      image = widgets.Image(\n",
        "          value=img,\n",
        "          width=420,\n",
        "          height=420\n",
        "      )\n",
        "      text_area = widgets.Textarea(value=text, description='', disabled=False, layout={'width': '300px', 'height': '120px'})\n",
        "\n",
        "\n",
        "      def update_text(text):\n",
        "          with open(CAPTIONS_DIR+\"/\"+name + '.txt', 'w') as f:\n",
        "              f.write(text)\n",
        "\n",
        "      button = widgets.Button(description='Save', button_style='success')\n",
        "      button.on_click(lambda b: update_text(text_area.value))\n",
        "\n",
        "      return widgets.VBox([widgets.HBox([image, text_area, button])])\n",
        "\n",
        "\n",
        "paths = os.listdir(INSTANCE_DIR)\n",
        "widgets_l = widgets.Select(options=[\"Select an instance image to caption\"]+paths, rows=25)\n",
        "\n",
        "\n",
        "out = widgets.Output()\n",
        "\n",
        "def click(change):\n",
        "    with out:\n",
        "        out.clear_output()\n",
        "        display(Caption(change.new))\n",
        "\n",
        "widgets_l.observe(click, names='value')\n",
        "display(widgets.HBox([widgets_l, out]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnmQYfZilzY6"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "1-9QbkfAVYYU"
      },
      "outputs": [],
      "source": [
        "#@markdown ---\n",
        "#@markdown #Start DreamBooth\n",
        "#@markdown ---\n",
        "import os\n",
        "from IPython.display import clear_output\n",
        "from google.colab import runtime\n",
        "from subprocess import getoutput\n",
        "import time\n",
        "import random\n",
        "\n",
        "if os.path.exists(INSTANCE_DIR+\"/.ipynb_checkpoints\"):\n",
        "  %rm -r $INSTANCE_DIR\"/.ipynb_checkpoints\"\n",
        "\n",
        "if os.path.exists(CAPTIONS_DIR+\"/.ipynb_checkpoints\"):\n",
        "  %rm -r $CAPTIONS_DIR\"/.ipynb_checkpoints\"\n",
        "\n",
        "Resume_Training = False #@param {type:\"boolean\"}\n",
        "\n",
        "if resume and not Resume_Training:\n",
        "  print('\u001b[1;31mOverwrite your previously trained model ? answering \"yes\" will train a new model, answering \"no\" will resume the training of the previous model?  yes or no ?\u001b[0m')\n",
        "  while True:\n",
        "    ansres=input('')\n",
        "    if ansres=='no':\n",
        "      Resume_Training = True\n",
        "      break\n",
        "    elif ansres=='yes':\n",
        "      Resume_Training = False\n",
        "      resume= False\n",
        "      break\n",
        "\n",
        "while not Resume_Training and MODEL_NAME==\"\":\n",
        "  print('\u001b[1;31mNo model found, use the \"Model Download\" cell to download a model.')\n",
        "  time.sleep(5)\n",
        "\n",
        "#@markdown  - If you're not satisfied with the result, check this box, run again the cell and it will continue training the current model.\n",
        "\n",
        "MODELT_NAME=MODEL_NAME\n",
        "\n",
        "UNet_Training_Steps=1500 #@param{type: 'number'}\n",
        "UNet_Learning_Rate = 2e-6 #@param [\"2e-5\",\"1e-5\",\"9e-6\",\"8e-6\",\"7e-6\",\"6e-6\",\"5e-6\", \"4e-6\", \"3e-6\", \"2e-6\"] {type:\"raw\"}\n",
        "untlr=UNet_Learning_Rate\n",
        "\n",
        "#@markdown - These default settings are for a dataset of 10 pictures which is enough for training a face, start with 1500 or lower, test the model, if not enough, resume training for 200 steps, keep testing until you get the desired output, `set it to 0 to train only the text_encoder`.\n",
        "\n",
        "Text_Encoder_Training_Steps=350 #@param{type: 'number'}\n",
        "\n",
        "#@markdown - 200-450 steps is enough for a small dataset, keep this number small to avoid overfitting, set to 0 to disable, `set it to 0 before resuming training if it is already trained`.\n",
        "\n",
        "Text_Encoder_Learning_Rate = 1e-6 #@param [\"2e-6\", \"1e-6\",\"8e-7\",\"6e-7\",\"5e-7\",\"4e-7\"] {type:\"raw\"}\n",
        "txlr=Text_Encoder_Learning_Rate\n",
        "\n",
        "#@markdown - Learning rate for the text_encoder, keep it low to avoid overfitting (1e-6 is higher than 4e-7)\n",
        "\n",
        "\n",
        "trnonltxt=\"\"\n",
        "if UNet_Training_Steps==0:\n",
        "   trnonltxt=\"--train_only_text_encoder\"\n",
        "\n",
        "Seed=''\n",
        "\n",
        "ofstnse=\"\"\n",
        "Offset_Noise = False #@param {type:\"boolean\"}\n",
        "#@markdown - Always use it for style training.\n",
        "\n",
        "if Offset_Noise:\n",
        "  ofstnse=\"--offset_noise\"\n",
        "\n",
        "External_Captions = False #@param {type:\"boolean\"}\n",
        "#@markdown - Get the captions from a text file for each instance image.\n",
        "extrnlcptn=\"\"\n",
        "if External_Captions:\n",
        "  extrnlcptn=\"--external_captions\"\n",
        "\n",
        "Resolution = \"512\" #@param [\"512\", \"576\", \"640\", \"704\", \"768\", \"832\", \"896\", \"960\", \"1024\"]\n",
        "Res=int(Resolution)\n",
        "\n",
        "#@markdown - Higher resolution = Higher quality, make sure the instance images are cropped to this selected size (or larger).\n",
        "\n",
        "fp16 = True\n",
        "\n",
        "if Seed =='' or Seed=='0':\n",
        "  Seed=random.randint(1, 999999)\n",
        "else:\n",
        "  Seed=int(Seed)\n",
        "\n",
        "if fp16:\n",
        "  prec=\"fp16\"\n",
        "else:\n",
        "  prec=\"no\"\n",
        "\n",
        "precision=prec\n",
        "\n",
        "resuming=\"\"\n",
        "if Resume_Training and os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n",
        "  MODELT_NAME=OUTPUT_DIR\n",
        "  print('\u001b[1;32mResuming Training...\u001b[0m')\n",
        "  resuming=\"Yes\"\n",
        "elif Resume_Training and not os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n",
        "  print('\u001b[1;31mPrevious model not found, training a new model...\u001b[0m')\n",
        "  MODELT_NAME=MODEL_NAME\n",
        "  while MODEL_NAME==\"\":\n",
        "    print('\u001b[1;31mNo model found, use the \"Model Download\" cell to download a model.')\n",
        "    time.sleep(5)\n",
        "\n",
        "V2=False\n",
        "if os.path.getsize(MODELT_NAME+\"/text_encoder/pytorch_model.bin\") > 670901463:\n",
        "  V2=True\n",
        "\n",
        "s = getoutput('nvidia-smi')\n",
        "GCUNET=\"--gradient_checkpointing\"\n",
        "TexRes=Res\n",
        "if Res<=768:\n",
        "  GCUNET=\"\"\n",
        "\n",
        "if V2:\n",
        "  if Res>704:\n",
        "    GCUNET=\"--gradient_checkpointing\"\n",
        "  if Res>576:\n",
        "    TexRes=576\n",
        "\n",
        "if 'A100' in s :\n",
        "   GCUNET=\"\"\n",
        "   TexRes=Res\n",
        "\n",
        "\n",
        "Enable_text_encoder_training= True\n",
        "\n",
        "if Text_Encoder_Training_Steps==0 :\n",
        "   Enable_text_encoder_training= False\n",
        "else:\n",
        "  stptxt=Text_Encoder_Training_Steps\n",
        "\n",
        "\n",
        "#@markdown ---------------------------\n",
        "Save_Checkpoint_Every_n_Steps = False #@param {type:\"boolean\"}\n",
        "Save_Checkpoint_Every=500 #@param{type: 'number'}\n",
        "if Save_Checkpoint_Every==None:\n",
        "  Save_Checkpoint_Every=1\n",
        "#@markdown - Minimum 200 steps between each save.\n",
        "stp=0\n",
        "Start_saving_from_the_step=500 #@param{type: 'number'}\n",
        "if Start_saving_from_the_step==None:\n",
        "  Start_saving_from_the_step=0\n",
        "if (Start_saving_from_the_step < 200):\n",
        "  Start_saving_from_the_step=Save_Checkpoint_Every\n",
        "stpsv=Start_saving_from_the_step\n",
        "if Save_Checkpoint_Every_n_Steps:\n",
        "  stp=Save_Checkpoint_Every\n",
        "#@markdown - Start saving intermediary checkpoints from this step.\n",
        "\n",
        "Disconnect_after_training=False #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown - Auto-disconnect from google colab after the training to avoid wasting compute units.\n",
        "\n",
        "def dump_only_textenc(trnonltxt, MODELT_NAME, INSTANCE_DIR, OUTPUT_DIR, PT, Seed, precision, Training_Steps):\n",
        "\n",
        "    !accelerate launch /content/diffusers/examples/dreambooth/train_dreambooth.py \\\n",
        "    $trnonltxt \\\n",
        "    $extrnlcptn \\\n",
        "    $ofstnse \\\n",
        "    --image_captions_filename \\\n",
        "    --train_text_encoder \\\n",
        "    --dump_only_text_encoder \\\n",
        "    --pretrained_model_name_or_path=\"$MODELT_NAME\" \\\n",
        "    --instance_data_dir=\"$INSTANCE_DIR\" \\\n",
        "    --output_dir=\"$OUTPUT_DIR\" \\\n",
        "    --captions_dir=\"$CAPTIONS_DIR\" \\\n",
        "    --instance_prompt=\"$PT\" \\\n",
        "    --seed=$Seed \\\n",
        "    --resolution=$TexRes \\\n",
        "    --mixed_precision=$precision \\\n",
        "    --train_batch_size=1 \\\n",
        "    --gradient_accumulation_steps=1 --gradient_checkpointing \\\n",
        "    --use_8bit_adam \\\n",
        "    --learning_rate=$txlr \\\n",
        "    --lr_scheduler=\"linear\" \\\n",
        "    --lr_warmup_steps=0 \\\n",
        "    --max_train_steps=$Training_Steps\n",
        "\n",
        "def train_only_unet(stpsv, stp, SESSION_DIR, MODELT_NAME, INSTANCE_DIR, OUTPUT_DIR, PT, Seed, Res, precision, Training_Steps):\n",
        "    clear_output()\n",
        "    if resuming==\"Yes\":\n",
        "      print('\u001b[1;32mResuming Training...\u001b[0m')\n",
        "    print('\u001b[1;33mTraining the UNet...\u001b[0m')\n",
        "    !accelerate launch /content/diffusers/examples/dreambooth/train_dreambooth.py \\\n",
        "    $extrnlcptn \\\n",
        "    $ofstnse \\\n",
        "    --image_captions_filename \\\n",
        "    --train_only_unet \\\n",
        "    --save_starting_step=$stpsv \\\n",
        "    --save_n_steps=$stp \\\n",
        "    --Session_dir=$SESSION_DIR \\\n",
        "    --pretrained_model_name_or_path=\"$MODELT_NAME\" \\\n",
        "    --instance_data_dir=\"$INSTANCE_DIR\" \\\n",
        "    --output_dir=\"$OUTPUT_DIR\" \\\n",
        "    --captions_dir=\"$CAPTIONS_DIR\" \\\n",
        "    --instance_prompt=\"$PT\" \\\n",
        "    --seed=$Seed \\\n",
        "    --resolution=$Res \\\n",
        "    --mixed_precision=$precision \\\n",
        "    --train_batch_size=1 \\\n",
        "    --gradient_accumulation_steps=1 $GCUNET \\\n",
        "    --use_8bit_adam \\\n",
        "    --learning_rate=$untlr \\\n",
        "    --lr_scheduler=\"linear\" \\\n",
        "    --lr_warmup_steps=0 \\\n",
        "    --max_train_steps=$Training_Steps\n",
        "\n",
        "\n",
        "if Enable_text_encoder_training :\n",
        "  print('\u001b[1;33mTraining the text encoder...\u001b[0m')\n",
        "  if os.path.exists(OUTPUT_DIR+'/'+'text_encoder_trained'):\n",
        "    %rm -r $OUTPUT_DIR\"/text_encoder_trained\"\n",
        "  dump_only_textenc(trnonltxt, MODELT_NAME, INSTANCE_DIR, OUTPUT_DIR, PT, Seed, precision, Training_Steps=stptxt)\n",
        "\n",
        "\n",
        "if UNet_Training_Steps!=0:\n",
        "  train_only_unet(stpsv, stp, SESSION_DIR, MODELT_NAME, INSTANCE_DIR, OUTPUT_DIR, PT, Seed, Res, precision, Training_Steps=UNet_Training_Steps)\n",
        "\n",
        "if UNet_Training_Steps==0 and Text_Encoder_Training_Steps==0 :\n",
        "  print('\u001b[1;32mNothing to do')\n",
        "else:\n",
        "  if os.path.exists('/content/models/'+INSTANCE_NAME+'/unet/diffusion_pytorch_model.bin'):\n",
        "    prc=\"--fp16\" if precision==\"fp16\" else \"\"\n",
        "    !python /content/diffusers/scripts/convertosdv2.py $prc $OUTPUT_DIR $SESSION_DIR/$Session_Name\".ckpt\"\n",
        "    clear_output()\n",
        "    if os.path.exists(SESSION_DIR+\"/\"+INSTANCE_NAME+'.ckpt'):\n",
        "      clear_output()\n",
        "      print(\"\u001b[1;32mDONE, the CKPT model is in your Gdrive in the sessions folder\")\n",
        "      if Disconnect_after_training :\n",
        "        time.sleep(20)\n",
        "        runtime.unassign()\n",
        "    else:\n",
        "      print(\"\u001b[1;31mSomething went wrong\")\n",
        "  else:\n",
        "    print(\"\u001b[1;31mSomething went wrong\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehi1KKs-l-ZS"
      },
      "source": [
        "# Test The Trained Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "iAZGngFcI8hq"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import sys\n",
        "import fileinput\n",
        "from IPython.display import clear_output\n",
        "from subprocess import getoutput\n",
        "from IPython.utils import capture\n",
        "from pyngrok import ngrok, conf\n",
        "import base64\n",
        "\n",
        "blasphemy=base64.b64decode((\"d2VidWk=\")).decode('ascii')\n",
        "\n",
        "Previous_Session=\"\" #@param{type: 'string'}\n",
        "\n",
        "#@markdown - Leave empty if you want to use the current trained model.\n",
        "\n",
        "Use_Custom_Path = False #@param {type:\"boolean\"}\n",
        "\n",
        "try:\n",
        "  INSTANCE_NAME\n",
        "  INSTANCET=INSTANCE_NAME\n",
        "except:\n",
        "  pass\n",
        "#@markdown - if checked, an input box will ask the full path to a desired model.\n",
        "\n",
        "if Previous_Session!=\"\":\n",
        "  INSTANCET=Previous_Session\n",
        "  INSTANCET=INSTANCET.replace(\" \",\"_\")\n",
        "\n",
        "if Use_Custom_Path:\n",
        "  try:\n",
        "    INSTANCET\n",
        "    del INSTANCET\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "try:\n",
        "  INSTANCET\n",
        "  if Previous_Session!=\"\":\n",
        "    path_to_trained_model='/content/gdrive/MyDrive/Fast-Dreambooth/Sessions/'+Previous_Session+\"/\"+Previous_Session+'.ckpt'\n",
        "  else:\n",
        "    path_to_trained_model=SESSION_DIR+\"/\"+INSTANCET+'.ckpt'\n",
        "except:\n",
        "  print('\u001b[1;31mIt seems that you did not perform training during this session \u001b[1;32mor you chose to use a custom path,\\nprovide the full path to the model (including the name of the model):\\n')\n",
        "  path_to_trained_model=input()\n",
        "\n",
        "while not os.path.exists(path_to_trained_model):\n",
        "   print(\"\u001b[1;31mThe model doesn't exist on you Gdrive, use the file explorer to get the path : \")\n",
        "   path_to_trained_model=input()\n",
        "\n",
        "fgitclone = \"git clone --depth 1\"\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "    if not os.path.exists('/content/gdrive/MyDrive'):\n",
        "      !mkdir -p /content/gdrive/MyDrive\n",
        "\n",
        "if not os.path.exists('/content/gdrive/MyDrive/sd/stablediffusion'):\n",
        "    !wget -q -O /content/sd_rep.tar.zst https://huggingface.co/TheLastBen/dependencies/resolve/main/sd_rep.tar.zst\n",
        "    !tar -C  /content/gdrive/MyDrive --zstd -xf /content/sd_rep.tar.zst\n",
        "    !rm /content/sd_rep.tar.zst\n",
        "    clear_output()\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "  %cd /content/gdrive/MyDrive/sd\n",
        "  !git clone -q --branch master https://github.com/AUTOMATIC1111/stable-diffusion-$blasphemy\n",
        "  %cd stable-diffusion-$blasphemy\n",
        "  !mkdir cache\n",
        "  !sed -i 's@~/.cache@/content/gdrive/MyDrive/sd/stable-diffusion-{blasphemy}/cache@' /usr/local/lib/python3.11/dist-packages/transformers/utils/hub.py\n",
        "\n",
        "  clear_output()\n",
        "  !git reset --hard\n",
        "  time.sleep(1)\n",
        "  !rm webui.sh\n",
        "  !git pull\n",
        "  !git fetch --unshallow\n",
        "  !git checkout a9eab236d7e8afa4d6205127904a385b2c43bb24\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "  if not os.path.exists('/tools/node/bin/lt'):\n",
        "    !npm install -g localtunnel\n",
        "\n",
        "Ngrok_token = \"\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown - Input your ngrok token if you want to use ngrok server.\n",
        "\n",
        "Use_localtunnel = False #@param {type:\"boolean\"}\n",
        "\n",
        "User = \"\" #@param {type:\"string\"}\n",
        "Password= \"\" #@param {type:\"string\"}\n",
        "#@markdown - Add credentials to your Gradio interface (optional).\n",
        "\n",
        "auth=f\"--gradio-auth {User}:{Password}\"\n",
        "if User ==\"\" or Password==\"\":\n",
        "  auth=\"\"\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "  %cd modules\n",
        "  !wget -q -O paths.py https://github.com/TheLastBen/fast-stable-diffusion/raw/5632d2ef7fffd940976538d270854ec4faf26855/AUTOMATIC1111_files/paths.py\n",
        "  !wget -q -O extras.py https://github.com/AUTOMATIC1111/stable-diffusion-$blasphemy/raw/a9eab236d7e8afa4d6205127904a385b2c43bb24/modules/extras.py\n",
        "  !wget -q -O sd_models.py https://github.com/AUTOMATIC1111/stable-diffusion-$blasphemy/raw/a9eab236d7e8afa4d6205127904a385b2c43bb24/modules/sd_models.py\n",
        "  !wget -q -O /usr/local/lib/python3.11/dist-packages/gradio/blocks.py https://github.com/TheLastBen/fast-stable-diffusion/raw/7ff88eaa1fb4997bacd9845bd487f9a14335d625/AUTOMATIC1111_files/blocks.py\n",
        "  %cd /content/gdrive/MyDrive/sd/stable-diffusion-$blasphemy/\n",
        "\n",
        "  !sed -i \"s@os.path.splitext(checkpoint_file)@os.path.splitext(checkpoint_file); map_location='cuda'@\" /content/gdrive/MyDrive/sd/stable-diffusion-$blasphemy/modules/sd_models.py\n",
        "  !sed -i 's@ui.create_ui().*@ui.create_ui();shared.demo.queue(concurrency_count=999999,status_update_rate=0.1)@' /content/gdrive/MyDrive/sd/stable-diffusion-$blasphemy/webui.py\n",
        "  !sed -i \"s@map_location='cpu'@map_location='cuda'@\" /content/gdrive/MyDrive/sd/stable-diffusion-$blasphemy/modules/extras.py\n",
        "  !sed -i 's@print(\\\"No module.*@@' /content/gdrive/MyDrive/sd/stablediffusion/ldm/modules/diffusionmodules/model.py\n",
        "  !sed -i 's@\\\"quicksettings\\\": OptionInfo(.*@\"quicksettings\": OptionInfo(\"sd_model_checkpoint,  sd_vae, CLIP_stop_at_last_layers, inpainting_mask_weight, initial_noise_multiplier\", \"Quicksettings list\"),@' /content/gdrive/MyDrive/sd/stable-diffusion-$blasphemy/modules/shared.py\n",
        "\n",
        "share=''\n",
        "if Ngrok_token!=\"\":\n",
        "  ngrok.kill()\n",
        "  srv=ngrok.connect(7860, pyngrok_config=conf.PyngrokConfig(auth_token=Ngrok_token) , bind_tls=True).public_url\n",
        "\n",
        "  for line in fileinput.input('/usr/local/lib/python3.11/dist-packages/gradio/blocks.py', inplace=True):\n",
        "    if line.strip().startswith('self.server_name ='):\n",
        "        line = f'            self.server_name = \"{srv[8:]}\"\\n'\n",
        "    if line.strip().startswith('self.protocol = \"https\"'):\n",
        "        line = '            self.protocol = \"https\"\\n'\n",
        "    if line.strip().startswith('if self.local_url.startswith(\"https\") or self.is_colab'):\n",
        "        line = ''\n",
        "    if line.strip().startswith('else \"http\"'):\n",
        "        line = ''\n",
        "    sys.stdout.write(line)\n",
        "\n",
        "elif Use_localtunnel:\n",
        "  with capture.capture_output() as cap:\n",
        "    share=''\n",
        "    %cd /content\n",
        "    !nohup lt --port 7860 > srv.txt 2>&1 &\n",
        "    time.sleep(2)\n",
        "    !grep -o 'https[^ ]*' /content/srv.txt >srvr.txt\n",
        "    time.sleep(2)\n",
        "    srv= getoutput('cat /content/srvr.txt')\n",
        "\n",
        "    for line in fileinput.input('/usr/local/lib/python3.11/dist-packages/gradio/blocks.py', inplace=True):\n",
        "      if line.strip().startswith('self.server_name ='):\n",
        "          line = f'            self.server_name = \"{srv[8:]}\"\\n'\n",
        "      if line.strip().startswith('self.protocol = \"https\"'):\n",
        "          line = '            self.protocol = \"https\"\\n'\n",
        "      if line.strip().startswith('if self.local_url.startswith(\"https\") or self.is_colab'):\n",
        "          line = ''\n",
        "      if line.strip().startswith('else \"http\"'):\n",
        "          line = ''\n",
        "      sys.stdout.write(line)\n",
        "\n",
        "    !rm /content/srv.txt /content/srvr.txt\n",
        "    %cd /content/gdrive/MyDrive/sd/stable-diffusion-$blasphemy\n",
        "\n",
        "else:\n",
        "  share='--share'\n",
        "\n",
        "configf=\"--api --disable-safe-unpickle --enable-insecure-extension-access --no-half-vae --opt-sdp-attention --no-download-sd-model --disable-console-progressbars\"\n",
        "\n",
        "clear_output()\n",
        "\n",
        "if os.path.isfile(path_to_trained_model):\n",
        "  !python /content/gdrive/MyDrive/sd/stable-diffusion-$blasphemy/webui.py $share --ckpt \"$path_to_trained_model\" $auth $configf\n",
        "else:\n",
        "  !python /content/gdrive/MyDrive/sd/stable-diffusion-$blasphemy/webui.py $share --ckpt-dir \"$path_to_trained_model\" $auth $configf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "iVqNi8IDzA1Z"
      },
      "outputs": [],
      "source": [
        "#@markdown #Free Gdrive Space\n",
        "\n",
        "#@markdown Display the list of sessions from your gdrive and choose which ones to remove.\n",
        "\n",
        "import ipywidgets as widgets\n",
        "\n",
        "Sessions=os.listdir(\"/content/gdrive/MyDrive/Fast-Dreambooth/Sessions\")\n",
        "\n",
        "s = widgets.Select(\n",
        "    options=Sessions,\n",
        "    rows=5,\n",
        "    description='',\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "out=widgets.Output()\n",
        "\n",
        "d = widgets.Button(\n",
        "    description='Remove',\n",
        "    disabled=False,\n",
        "    button_style='warning',\n",
        "    tooltip='Removet the selected session',\n",
        "    icon='warning'\n",
        ")\n",
        "\n",
        "def rem(d):\n",
        "    with out:\n",
        "        if s.value is not None:\n",
        "            clear_output()\n",
        "            print(\"\u001b[1;33mTHE SESSION \u001b[1;31m\"+s.value+\" \u001b[1;33mHAS BEEN REMOVED FROM YOUR GDRIVE\")\n",
        "            !rm -r '/content/gdrive/MyDrive/Fast-Dreambooth/Sessions/{s.value}'\n",
        "            s.options=os.listdir(\"/content/gdrive/MyDrive/Fast-Dreambooth/Sessions\")\n",
        "        else:\n",
        "            d.close()\n",
        "            s.close()\n",
        "            clear_output()\n",
        "            print(\"\u001b[1;32mNOTHING TO REMOVE\")\n",
        "\n",
        "d.on_click(rem)\n",
        "if s.value is not None:\n",
        "    display(s,d,out)\n",
        "else:\n",
        "    print(\"\u001b[1;32mNOTHING TO REMOVE\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "bbKbx185zqlz",
        "AaLtXBbPleBr"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}